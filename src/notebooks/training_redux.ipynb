{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58f6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b149ddb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:33,716 [INFO] Starting the model training process...\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Starting the model training process...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f57db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "# Create a python function to gather model metrics and save them to a file\n",
    "def save_model_metrics(y_true, y_pred, y_proba, model_name):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_proba[:, 1]),\n",
    "        'average_precision': average_precision_score(y_true, y_proba[:, 1])\n",
    "    }\n",
    "    logger.info(f\"Model metrics for {model_name}: {metrics}\")\n",
    "    return metrics\n",
    "# Save the model metrics to a file\n",
    "def save_metrics_to_file(metrics, model_name):\n",
    "    with open(f\"{model_name}_metrics.txt\", \"w\") as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    logger.info(f\"Model metrics saved to {model_name}_metrics.txt\")\n",
    "\n",
    "def evaluate_model(model, out_prefix, X_train, y_train, X_test, y_test, X_val = None, y_val = None, folds = None):\n",
    "\n",
    "    # Initialize the StratifiedKFold object\n",
    "    if folds:\n",
    "        skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=99)\n",
    "\n",
    "    # Perform cross-validation on the training set\n",
    "    y_pred = cross_val_predict(model, X_train, y_train, cv=skf if folds else None)\n",
    "    y_proba = model.predict_proba(X_train)\n",
    "    # Calculate the metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_train, y_pred),\n",
    "        'recall': recall_score(y_train, y_pred),\n",
    "        'precision': precision_score(y_train, y_pred),\n",
    "        'f1': f1_score(y_train, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_train, y_proba[:, 1]),\n",
    "        'average_precision': average_precision_score(y_train, y_proba[:, 1])\n",
    "    }\n",
    "    # Save the metrics to a file\n",
    "    save_metrics_to_file(metrics, f\"{out_prefix}_cv\")\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_proba = model.predict_proba(X_test)\n",
    "    # Calculate the metrics\n",
    "    test_metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'recall': recall_score(y_test, y_test_pred),\n",
    "        'precision': precision_score(y_test, y_test_pred),\n",
    "        'f1': f1_score(y_test, y_test_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_test_proba[:, 1]),\n",
    "        'average_precision': average_precision_score(y_test, y_test_proba[:, 1])\n",
    "    }\n",
    "    # Save the metrics to a file\n",
    "    save_metrics_to_file(test_metrics, f\"{out_prefix}_test\")\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_proba = model.predict_proba(X_val)\n",
    "    # Calculate the metrics\n",
    "    val_metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'recall': recall_score(y_val, y_val_pred),\n",
    "        'precision': precision_score(y_val, y_val_pred),\n",
    "        'f1': f1_score(y_val, y_val_pred),\n",
    "        'roc_auc': roc_auc_score(y_val, y_val_proba[:, 1]),\n",
    "        'average_precision': average_precision_score(y_val, y_val_proba[:, 1])\n",
    "    }\n",
    "    # Save the metrics to a file\n",
    "    save_metrics_to_file(val_metrics, f\"{out_prefix}_val\")\n",
    "\n",
    "    # Calculate the average metrics and standard deviation\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean([metrics['accuracy'], test_metrics['accuracy'], val_metrics['accuracy']]),\n",
    "        'recall': np.mean([metrics['recall'], test_metrics['recall'], val_metrics['recall']]),\n",
    "        'precision': np.mean([metrics['precision'], test_metrics['precision'], val_metrics['precision']]),\n",
    "        'f1': np.mean([metrics['f1'], test_metrics['f1'], val_metrics['f1']]),\n",
    "        'roc_auc': np.mean([metrics['roc_auc'], test_metrics['roc_auc'], val_metrics['roc_auc']]),\n",
    "        'average_precision': np.mean([metrics['average_precision'], test_metrics['average_precision'], val_metrics['average_precision']])\n",
    "    }\n",
    "    std_metrics = {\n",
    "        'accuracy': np.std([metrics['accuracy'], test_metrics['accuracy'], val_metrics['accuracy']]),\n",
    "        'recall': np.std([metrics['recall'], test_metrics['recall'], val_metrics['recall']]),\n",
    "        'precision': np.std([metrics['precision'], test_metrics['precision'], val_metrics['precision']]),\n",
    "        'f1': np.std([metrics['f1'], test_metrics['f1'], val_metrics['f1']]),\n",
    "        'roc_auc': np.std([metrics['roc_auc'], test_metrics['roc_auc'], val_metrics['roc_auc']]),\n",
    "        'average_precision': np.std([metrics['average_precision'], test_metrics['average_precision'], val_metrics['average_precision']])\n",
    "    }\n",
    "\n",
    "    final_metrics = {\n",
    "        'accuracy': (avg_metrics['accuracy'], '±', std_metrics['accuracy']),\n",
    "        'recall': (avg_metrics['recall'], '±', std_metrics['recall']),\n",
    "        'precision': (avg_metrics['precision'], '±', std_metrics['precision']),\n",
    "        'f1': (avg_metrics['f1'], '±', std_metrics['f1']),\n",
    "        'roc_auc': (avg_metrics['roc_auc'], '±', std_metrics['roc_auc']),\n",
    "        'average_precision': (avg_metrics['average_precision'], '±', std_metrics['average_precision'])\n",
    "    }\n",
    "    # Save the final metrics to a file\n",
    "    save_metrics_to_file(final_metrics, f\"{out_prefix}_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c5094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive samples -- lncRNAs\n",
    "df_pos = pd.read_parquet('/home/chlab/flync/src/data/ncr_dim_redux.parquet')\n",
    "\n",
    "\n",
    "# Load negative samples -- protein coding genes\n",
    "df_neg = pd.read_parquet('/home/chlab/flync/src/data/pcg_dim_redux.parquet')\n",
    "\n",
    "# Target column (Binary classification)\n",
    "label = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e54e394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:36,399 [INFO] Columns not used as features: ['chromosome', 'start', 'end', 'transcript_id', 'exon_number', 'gene_name', 'sequence', 'vrna_structure', 'cpat_orf_len']\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that are not features\n",
    "cols_not_features = ['chromosome', 'start', 'end', 'transcript_id', 'exon_number', 'gene_name', 'sequence', 'vrna_structure', 'cpat_orf_len']\n",
    "\n",
    "logging.info(f\"Columns not used as features: {cols_not_features}\")\n",
    "df_pos = df_pos.drop(columns=cols_not_features)\n",
    "df_neg = df_neg.drop(columns=cols_not_features)\n",
    "init_pos_records = df_pos.shape[0]\n",
    "init_neg_records = df_neg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9d9a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:36,543 [INFO] DataFrames merged. Shape: (103902, 41)\n",
      "2025-05-21 17:00:36,544 [INFO] DataFrame columns: ['length', 'mean_gc', 'cov_tfbs', 'max_tfbs', 'cov_remap', 'max_remap', 'cov_tss_plus', 'max_tss_plus', 'sum_tss_plus', 'cov_tss_minus', 'min_tss_minus', 'sum_tss_minus', 'cov_s2_pol2', 'sum_s2_pol2', 'max_s2_pol2', 'cov_h3k4me3', 'mean_h3k4me3', 'sum_h3k4me3', 'cov_epdnew', 'max_epdnew', 'mean_pcons27', 'std_pcons27', 'sum_pcons27', 'mean_phylocons124', 'std__phylocons124', 'sum__phylocons124', 'cpat_cod_prob', 'cpat_fickett_score', 'cpat_hexamer_score', 'vrna_mfe', '3mer_SVD1', '4mer_SVD1', '5mer_SVD1', '6mer_SVD1', '7mer_SVD1', '8mer_SVD1', '9mer_SVD1', '10mer_SVD1', '11mer_SVD1', '12mer_SVD1', 'y']\n",
      "2025-05-21 17:00:36,547 [INFO] DataFrame dtypes: length                  int64\n",
      "mean_gc               float64\n",
      "cov_tfbs              float64\n",
      "max_tfbs              float64\n",
      "cov_remap             float64\n",
      "max_remap             float64\n",
      "cov_tss_plus          float64\n",
      "max_tss_plus          float64\n",
      "sum_tss_plus          float64\n",
      "cov_tss_minus         float64\n",
      "min_tss_minus         float64\n",
      "sum_tss_minus         float64\n",
      "cov_s2_pol2           float64\n",
      "sum_s2_pol2           float64\n",
      "max_s2_pol2           float64\n",
      "cov_h3k4me3           float64\n",
      "mean_h3k4me3          float64\n",
      "sum_h3k4me3           float64\n",
      "cov_epdnew            float64\n",
      "max_epdnew            float64\n",
      "mean_pcons27          float64\n",
      "std_pcons27           float64\n",
      "sum_pcons27           float64\n",
      "mean_phylocons124     float64\n",
      "std__phylocons124     float64\n",
      "sum__phylocons124     float64\n",
      "cpat_cod_prob         float64\n",
      "cpat_fickett_score    float64\n",
      "cpat_hexamer_score    float64\n",
      "vrna_mfe              float64\n",
      "3mer_SVD1             float64\n",
      "4mer_SVD1             float64\n",
      "5mer_SVD1             float64\n",
      "6mer_SVD1             float64\n",
      "7mer_SVD1             float64\n",
      "8mer_SVD1             float64\n",
      "9mer_SVD1             float64\n",
      "10mer_SVD1            float64\n",
      "11mer_SVD1            float64\n",
      "12mer_SVD1            float64\n",
      "y                        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check if dfs can be merged\n",
    "if df_pos.shape[1] != df_neg.shape[1]:\n",
    "    logger.error(\"DataFrames have different number of columns after dropping non-feature columns.\")\n",
    "    raise ValueError(\"DataFrames have different number of columns after dropping non-feature columns.\")\n",
    "# Check if the columns are the same\n",
    "if not all(df_pos.columns == df_neg.columns):\n",
    "    logger.error(\"DataFrames have different columns after dropping non-feature columns.\")\n",
    "    raise ValueError(\"DataFrames have different columns after dropping non-feature columns.\")\n",
    "\n",
    "df = pd.concat([df_pos, df_neg], ignore_index=True)\n",
    "del df_pos, df_neg\n",
    "logger.info(f\"DataFrames merged. Shape: {df.shape}\")\n",
    "logger.info(f\"DataFrame columns: {df.columns.tolist()}\")\n",
    "logger.info(f\"DataFrame dtypes: {df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6c098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:36,959 [INFO] Duplicates removed. Shape: (103902, 41)\n",
      "2025-05-21 17:00:36,961 [INFO] Percentage of records dropped due to duplicates: 0.00%\n",
      "2025-05-21 17:00:36,980 [INFO] Columns with NAs: \n",
      "cov_tss_plus           1498\n",
      "max_tss_plus           1498\n",
      "sum_tss_plus           1802\n",
      "cov_tss_minus          1487\n",
      "min_tss_minus          1487\n",
      "sum_tss_minus          1744\n",
      "cov_s2_pol2            8012\n",
      "sum_s2_pol2            8120\n",
      "max_s2_pol2            8012\n",
      "cov_h3k4me3            9026\n",
      "mean_h3k4me3           9026\n",
      "sum_h3k4me3           11899\n",
      "cov_epdnew              151\n",
      "max_epdnew              151\n",
      "mean_pcons27            181\n",
      "std_pcons27             181\n",
      "sum_pcons27             229\n",
      "mean_phylocons124        20\n",
      "std__phylocons124        22\n",
      "sum__phylocons124        39\n",
      "cpat_cod_prob          7250\n",
      "cpat_fickett_score     7250\n",
      "cpat_hexamer_score     7250\n",
      "vrna_mfe              19447\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "logger.info(f\"Duplicates removed. Shape: {df.shape}\")\n",
    "\n",
    "# Percentage of records dropped due to duplicates\n",
    "duplicates_percentage = (1 - df.shape[0] / (init_pos_records + init_neg_records)) * 100\n",
    "logger.info(f\"Percentage of records dropped due to duplicates: {duplicates_percentage:.2f}%\")\n",
    "\n",
    "# Count NAs per each column\n",
    "na_counts = df.isna().sum()\n",
    "na_counts = na_counts[na_counts > 0]\n",
    "if not na_counts.empty:\n",
    "    logger.info(f\"Columns with NAs: \\n{na_counts}\")\n",
    "else:\n",
    "    logger.info(\"No NAs found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1579a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:37,007 [INFO] Filling NAs in column cov_tss_plus with 0\n",
      "2025-05-21 17:00:37,011 [INFO] Filling NAs in column max_tss_plus with 0\n",
      "2025-05-21 17:00:37,017 [INFO] Filling NAs in column sum_tss_plus with 0\n",
      "2025-05-21 17:00:37,022 [INFO] Filling NAs in column cov_tss_minus with 0\n",
      "2025-05-21 17:00:37,027 [INFO] Filling NAs in column min_tss_minus with 0\n",
      "2025-05-21 17:00:37,033 [INFO] Filling NAs in column sum_tss_minus with 0\n",
      "2025-05-21 17:00:37,040 [INFO] Filling NAs in column cov_s2_pol2 with 0\n",
      "2025-05-21 17:00:37,045 [INFO] Filling NAs in column sum_s2_pol2 with 0\n",
      "2025-05-21 17:00:37,049 [INFO] Filling NAs in column max_s2_pol2 with 0\n",
      "2025-05-21 17:00:37,052 [INFO] Filling NAs in column cov_h3k4me3 with 0\n",
      "2025-05-21 17:00:37,056 [INFO] Filling NAs in column mean_h3k4me3 with 0\n",
      "2025-05-21 17:00:37,061 [INFO] Filling NAs in column sum_h3k4me3 with 0\n",
      "2025-05-21 17:00:37,067 [INFO] Filling NAs in column cov_epdnew with 0\n",
      "2025-05-21 17:00:37,073 [INFO] Filling NAs in column max_epdnew with 0\n",
      "2025-05-21 17:00:37,079 [INFO] Filling NAs in column mean_pcons27 with 0\n",
      "2025-05-21 17:00:37,083 [INFO] Filling NAs in column std_pcons27 with 0\n",
      "2025-05-21 17:00:37,088 [INFO] Filling NAs in column sum_pcons27 with 0\n",
      "2025-05-21 17:00:37,093 [INFO] Filling NAs in column mean_phylocons124 with 0\n",
      "2025-05-21 17:00:37,097 [INFO] Filling NAs in column std__phylocons124 with 0\n",
      "2025-05-21 17:00:37,102 [INFO] Filling NAs in column sum__phylocons124 with 0\n",
      "2025-05-21 17:00:37,107 [INFO] Filling NAs in column cpat_cod_prob with 0\n",
      "2025-05-21 17:00:37,114 [INFO] Filling NAs in column cpat_fickett_score with 0\n",
      "2025-05-21 17:00:37,120 [INFO] Filling NAs in column cpat_hexamer_score with 0\n",
      "2025-05-21 17:00:37,129 [INFO] Dropping rows with NAs in column vrna_mfe\n",
      "2025-05-21 17:00:37,161 [INFO] Rows with NAs in column vrna_mfe dropped. Shape: (84455, 41)\n",
      "2025-05-21 17:00:37,192 [INFO] Rows with vrna_mfe >= 0 dropped. Shape: (83019, 41)\n"
     ]
    }
   ],
   "source": [
    "# Logic for data cleaning:\n",
    "# 1. If columns are UCSC (BigWig or BigBed) statistics features or CPAT scores (no ORFs found), fill NAs with 0\n",
    "logic_op1 = (df.columns.str.startswith(tuple(['min_', 'max_', 'mean_', 'std_', 'sum_', 'cov_'])) | df.columns.str.startswith('cpat_'))\n",
    "for col in df.columns:\n",
    "    if col in df.columns[logic_op1]:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            logger.info(f\"Filling NAs in column {col} with 0\")\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "# 2. If columns are vrna_* features, drop rows with NAs. This seems to be the best approach as no structure was calculated for the sequence\n",
    "logic_op2 = df.columns.str.startswith('vrna_')\n",
    "for col in df.columns:\n",
    "    if col in df.columns[logic_op2]:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            logger.info(f\"Dropping rows with NAs in column {col}\")\n",
    "            df = df.dropna(subset=[col])\n",
    "            logger.info(f\"Rows with NAs in column {col} dropped. Shape: {df.shape}\")\n",
    "        # Drop values where `vrna_mfe` is not < 0\n",
    "        if col == 'vrna_mfe':\n",
    "            df = df[df[col] < 0]\n",
    "            logger.info(f\"Rows with vrna_mfe >= 0 dropped. Shape: {df.shape}\")\n",
    "\n",
    "# 3. If columns start with '0' or '1', drop rows with NAs. This seems to be the best approach as we have no counts for all required k-mers\n",
    "logic_op3 = df.columns.str.contains('SVD')\n",
    "for col in df.columns:\n",
    "    if col in df.columns[logic_op3]:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            logger.info(f\"Dropping rows with NAs in column {col}\")\n",
    "            df = df.dropna(subset=[col])\n",
    "            logger.info(f\"Rows with NAs in column {col} dropped. Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f26cf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:37,256 [INFO] Positive records before data cleaning: 5455, after: 5388\n",
      "2025-05-21 17:00:37,258 [INFO] Negative records before data cleaning: 98447, after: 77631\n",
      "2025-05-21 17:00:37,259 [INFO] Percentage of positive records lost: 1.23%\n",
      "2025-05-21 17:00:37,259 [INFO] Percentage of negative records lost: 21.14%\n"
     ]
    }
   ],
   "source": [
    "# Compare the current postive and negative instances with the ones before data cleaning\n",
    "final_pos_records = df[df['y'] == 1].shape[0]\n",
    "final_neg_records = df[df['y'] == 0].shape[0]\n",
    "logger.info(f\"Positive records before data cleaning: {init_pos_records}, after: {final_pos_records}\")\n",
    "logger.info(f\"Negative records before data cleaning: {init_neg_records}, after: {final_neg_records}\")\n",
    "# Log percentage of positive and negative records lost\n",
    "pos_records_lost = init_pos_records - final_pos_records\n",
    "neg_records_lost = init_neg_records - final_neg_records\n",
    "if init_pos_records > 0:\n",
    "    logger.info(f\"Percentage of positive records lost: {pos_records_lost / init_pos_records * 100:.2f}%\")\n",
    "if init_neg_records > 0:\n",
    "    logger.info(f\"Percentage of negative records lost: {neg_records_lost / init_neg_records * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7d5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[label])\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b2b550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:37,433 [INFO] Train set shape: (58113, 40), (58113,)\n",
      "2025-05-21 17:00:37,436 [INFO] Validation set shape: (12453, 40), (12453,)\n",
      "2025-05-21 17:00:37,438 [INFO] Test set shape: (12453, 40), (12453,)\n",
      "2025-05-21 17:00:37,443 [INFO] Train set target variable distribution: y\n",
      "False    0.935092\n",
      "True     0.064908\n",
      "Name: proportion, dtype: float64\n",
      "2025-05-21 17:00:37,447 [INFO] Validation set target variable distribution: y\n",
      "False    0.935116\n",
      "True     0.064884\n",
      "Name: proportion, dtype: float64\n",
      "2025-05-21 17:00:37,452 [INFO] Test set target variable distribution: y\n",
      "False    0.935116\n",
      "True     0.064884\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Train-test-validation split\n",
    "# 70% train, 15% validation, 15% test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=99)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=99)\n",
    "\n",
    "logger.info(f\"Train set shape: {X_train.shape}, {y_train.shape}\")\n",
    "logger.info(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
    "logger.info(f\"Test set shape: {X_test.shape}, {y_test.shape}\")\n",
    "# Check if the target variable is balanced\n",
    "logger.info(f\"Train set target variable distribution: {y_train.value_counts(normalize=True)}\")\n",
    "logger.info(f\"Validation set target variable distribution: {y_val.value_counts(normalize=True)}\")\n",
    "logger.info(f\"Test set target variable distribution: {y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb61ee8",
   "metadata": {},
   "source": [
    "# Evaluate which model algorithms should be considered for further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863f74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# # Split the data into Train, Test and Validation sets\n",
    "# # 70% for training, 15% for testing, 15% for validation\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "# logger.info(f\"Train set shape: {X_train.shape}, Test set shape: {X_test.shape}, Validation set shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b43efaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lz = LazyClassifier(predictions=True)\n",
    "# # Fit the model\n",
    "# models = df_lz.fit(X_train, X_test, y_train, y_test)\n",
    "# # Get the best model\n",
    "# best_model = models[0].iloc[0]\n",
    "# logger.info(f\"Best model: {best_model['Model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b57083",
   "metadata": {},
   "source": [
    "# Imbalanced training set\n",
    "Since there are a much less positive instances (lncRNAs) than negative instances (protein coding) we can\n",
    "1. Oversample the minority class -- lncRNAs\n",
    "2. Undersample the majority class -- protein coding\n",
    "3. Use imbalanced-resistant machine-learning algorithms (Random Forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d726491",
   "metadata": {},
   "source": [
    "## 1. Use SMOTE to oversample lncRNA instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc70ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:37,758 [INFO] Resampled dataset shape: (108682, 40), (108682,)\n"
     ]
    }
   ],
   "source": [
    "# Perform oversampling of the minority class\n",
    "smote = SMOTE(random_state=99)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "logger.info(f\"Resampled dataset shape: {X_smote.shape}, {y_smote.shape}\")\n",
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5704246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:00:44,916 [INFO] Random Forest classifier trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/chlab/flync/src/train/rf_model_smote_redux.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest classifier\n",
    "output_prefix = 'rf_model_smote_redux'\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=99,\n",
    "    n_jobs=16\n",
    ")\n",
    "rf.fit(X_smote, y_smote)\n",
    "logger.info(\"Random Forest classifier trained.\")\n",
    "# Save the model\n",
    "joblib.dump(rf, f'/home/chlab/flync/src/train/{output_prefix}.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1f53085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:01:09,867 [INFO] Model metrics saved to rf_model_smote_redux_cv_metrics.txt\n",
      "2025-05-21 17:01:10,005 [INFO] Model metrics saved to rf_model_smote_redux_test_metrics.txt\n",
      "2025-05-21 17:01:10,162 [INFO] Model metrics saved to rf_model_smote_redux_val_metrics.txt\n",
      "2025-05-21 17:01:10,164 [INFO] Model metrics saved to rf_model_smote_redux_final_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, output_prefix, X_smote, y_smote, X_test, y_test, X_val, y_val, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f35dccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:01:14,373 [INFO] XGBoost classifier trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/chlab/flync/src/train/xgb_model_smote_redux.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_prefix = 'xgb_model_smote_redux'\n",
    "\n",
    "# train an XGBoost classifier\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=99,\n",
    "    n_jobs=16\n",
    ")\n",
    "\n",
    "xgb.fit(X_smote, y_smote)\n",
    "logger.info(\"XGBoost classifier trained.\")\n",
    "# Save the model\n",
    "joblib.dump(xgb, f'/home/chlab/flync/src/train/{output_prefix}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b9f29c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:01:27,837 [INFO] Model metrics saved to xgb_model_smote_redux_cv_metrics.txt\n",
      "2025-05-21 17:01:27,881 [INFO] Model metrics saved to xgb_model_smote_redux_test_metrics.txt\n",
      "2025-05-21 17:01:27,923 [INFO] Model metrics saved to xgb_model_smote_redux_val_metrics.txt\n",
      "2025-05-21 17:01:27,925 [INFO] Model metrics saved to xgb_model_smote_redux_final_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(xgb, output_prefix, X_smote, y_smote, X_test, y_test, X_val, y_val, folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38357a2",
   "metadata": {},
   "source": [
    "## 2. Oversampling and Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67a3fdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:01:34,734 [INFO] Resampled dataset shape: (107446, 40), (107446,)\n"
     ]
    }
   ],
   "source": [
    "# Use SMOTETomek to balance the dataset\n",
    "smote_tomek = SMOTETomek(random_state=99)\n",
    "X_smote_tomek, y_smote_tomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "logger.info(f\"Resampled dataset shape: {X_smote_tomek.shape}, {y_smote_tomek.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05fb46a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:01:41,304 [INFO] Random Forest classifier trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/chlab/flync/src/train/rf_model_smote_tomek_redux.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_prefix = 'rf_model_smote_tomek_redux'\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=99,\n",
    "    n_jobs=16\n",
    ")\n",
    "rf.fit(X_smote_tomek, y_smote_tomek)\n",
    "logger.info(\"Random Forest classifier trained.\")\n",
    "# Save the model\n",
    "joblib.dump(rf, f'/home/chlab/flync/src/train/{output_prefix}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "789016e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:02:03,048 [INFO] Model metrics saved to rf_model_smote_tomek_redux_cv_metrics.txt\n",
      "2025-05-21 17:02:03,196 [INFO] Model metrics saved to rf_model_smote_tomek_redux_test_metrics.txt\n",
      "2025-05-21 17:02:03,342 [INFO] Model metrics saved to rf_model_smote_tomek_redux_val_metrics.txt\n",
      "2025-05-21 17:02:03,344 [INFO] Model metrics saved to rf_model_smote_tomek_redux_final_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, output_prefix, X_smote_tomek, y_smote_tomek, X_test, y_test, X_val, y_val, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0ff498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:02:08,058 [INFO] XGBoost classifier trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/chlab/flync/src/train/xgb_model_smote_tomek_redux.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_prefix = 'xgb_model_smote_tomek_redux'\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=99,\n",
    "    n_jobs=16\n",
    ")\n",
    "xgb.fit(X_smote_tomek, y_smote_tomek)\n",
    "logger.info(\"XGBoost classifier trained.\")\n",
    "# Save the model\n",
    "joblib.dump(xgb, f'/home/chlab/flync/src/train/{output_prefix}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f7188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:02:31,879 [INFO] Model metrics saved to xgb_model_smote_tomek_redux_cv_metrics.txt\n",
      "2025-05-21 17:02:32,026 [INFO] Model metrics saved to xgb_model_smote_tomek_redux_test_metrics.txt\n",
      "2025-05-21 17:02:32,175 [INFO] Model metrics saved to xgb_model_smote_tomek_redux_val_metrics.txt\n",
      "2025-05-21 17:02:32,178 [INFO] Model metrics saved to xgb_model_smote_tomek_redux_final_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, output_prefix, X_smote_tomek, y_smote_tomek, X_test, y_test, X_val, y_val, folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87e582",
   "metadata": {},
   "source": [
    "## 3. Do not change the data and use class wieghts to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cb75dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:02:34,710 [INFO] Random Forest classifier trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/chlab/flync/src/train/rf_model_redux.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_prefix = 'rf_model_redux'\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=99,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=16\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "logger.info(\"Random Forest classifier trained.\")\n",
    "# Save the model\n",
    "joblib.dump(rf, f'/home/chlab/flync/src/train/{output_prefix}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f56f919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:02:44,510 [INFO] Model metrics saved to rf_model_redux_cv_metrics.txt\n",
      "2025-05-21 17:02:44,681 [INFO] Model metrics saved to rf_model_redux_test_metrics.txt\n",
      "2025-05-21 17:02:44,834 [INFO] Model metrics saved to rf_model_redux_val_metrics.txt\n",
      "2025-05-21 17:02:44,837 [INFO] Model metrics saved to rf_model_redux_final_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, output_prefix, X_train, y_train, X_test, y_test, X_val, y_val, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f810826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:02:44,849 [INFO] Scale pos weight: 14.406415694591729\n",
      "2025-05-21 17:02:47,673 [INFO] XGBoost classifier trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/chlab/flync/src/train/xgb_model_redux.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_prefix = 'xgb_model_redux'\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "logger.info(f\"Scale pos weight: {scale_pos_weight}\")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=99,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    n_jobs=16\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "logger.info(\"XGBoost classifier trained.\")\n",
    "# Save the model\n",
    "joblib.dump(xgb, f'/home/chlab/flync/src/train/{output_prefix}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9fea33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:03:02,271 [INFO] Model metrics saved to xgb_model_redux_cv_metrics.txt\n",
      "2025-05-21 17:03:02,340 [INFO] Model metrics saved to xgb_model_redux_test_metrics.txt\n",
      "2025-05-21 17:03:02,425 [INFO] Model metrics saved to xgb_model_redux_val_metrics.txt\n",
      "2025-05-21 17:03:02,427 [INFO] Model metrics saved to xgb_model_redux_final_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(xgb, output_prefix, X_train, y_train, X_test, y_test, X_val, y_val, folds=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
