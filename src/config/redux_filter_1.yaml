# Batch Optimization Configuration File
# This file defines multiple dataset configurations for batch hyperparameter optimization

# Global defaults (can be overridden in individual configurations)
global_defaults:
  optimization_direction: "maximize"
  n_trials: 100
  random_state: 99
  job_timeout: 3600
  delay_between_jobs: 30
  project_name: "Flync Feature and Hyperparameter Optimization"
  debug: true
  threads: 20

# Storage configuration (optional - can be overridden per config)
storage:
  mlflow_uri: "http://localhost:5000"
  storage_url: "sqlite:///optuna.db"

# Default models and metrics (can be overridden per config)
default_models: ["randomforest", "xgboost", "lightgbm", "ebm"]
default_metric_combinations:
  - ["precision"]
  - ["f1"]
  - ["roc_auc"]
  - ["pr_auc"]
  - ["precision", "f1"]
  - ["f1", "roc_auc"]
  - ["roc_auc", "pr_auc"]

# Dataset configurations - each represents a different dataset with its own parameters
dataset_configs:

  redux_filter_1:
    name: "k-mer redux filter #1 dataset"
    description: "Dataset with k-mer counting dimentionality reduction using SVD into a single bin. Filter #1 applied: [dropping 'epdnew_' columns] (see feature_selection.ipynb)"
    
    # Dataset paths
    train_data: "src/data/X_train_redux_filter_1.parquet"
    test_data: "src/data/X_test_redux_filter_1.parquet"
    holdout_data: "src/data/X_val_redux_filter_1.parquet"
    target_column: "y"
    dataset_suffix: "redux_filter_1"

    # Experiment configuration
    experiment_name: "redux_filter_1"

    # Feature correlation analysis
    #analyze_correlations: true
    #correlation_threshold: 0.95
    # Alternative: drop_features_file: "features_to_drop.txt"
    
    # Tags specific to this dataset
    tags:
      dataset_imbalance_technique: "none"
      dataset_kmer_redux: "true"
      features_cpat: "true"
      features_regulators_mhe: "remap_tfbs"
      features_ss: "true"
      features_filter: "1"
    
    # Model/metric overrides (optional)
    models: ["randomforest", "xgboost", "lightgbm", "ebm"]
    metrics: 
      - ["precision"]
      - ["f1"] 
      - ["roc_auc"]
      - ["precision", "f1"]
      - ["pr_auc"]

  redux_filter_1_corr:
    name: "k-mer redux filter #1 dataset"
    description: "Dataset with k-mer counting dimentionality reduction using SVD into a single bin. Filter #1 applied: [dropping 'epdnew_' columns] (see feature_selection.ipynb)"
    
    # Dataset paths
    train_data: "src/data/X_train_redux_filter_1.parquet"
    test_data: "src/data/X_test_redux_filter_1.parquet"
    holdout_data: "src/data/X_val_redux_filter_1.parquet"
    target_column: "y"
    dataset_suffix: "redux_filter_1"

    # Experiment configuration
    experiment_name: "redux_filter_1"

    # Feature correlation analysis
    analyze_correlations: true
    correlation_threshold: 0.95
    # Alternative: drop_features_file: "features_to_drop.txt"
    
    # Tags specific to this dataset
    tags:
      dataset_imbalance_technique: "none"
      dataset_kmer_redux: "true"
      features_cpat: "true"
      features_regulators_mhe: "remap_tfbs"
      features_ss: "true"
      features_filter: "1"
    
    # Model/metric overrides (optional)
    models: ["randomforest", "xgboost", "lightgbm", "ebm"]
    metrics: 
      - ["precision"]
      - ["f1"] 
      - ["roc_auc"]
      - ["precision", "f1"]
      - ["pr_auc"]


advanced:
  # Custom model configurations per dataset
  # custom_model_configs:
  #   redux_raw:
  #     randomforest:
  #       n_trials: 100
  #     xgboost:
  #       n_trials: 150
  #     lightgbm:
  #       n_trials: 150
  #     ebm:
  #       n_trials: 60

  # Conditional execution rules
  execution_rules:
    # Skip EBM if dataset has more than 1000 features
    skip_ebm_large_datasets: true
    max_features_for_ebm: 1000
    
    # Auto-adjust trials based on dataset size
    auto_adjust_trials: true
    min_trials: 50
    max_trials: 300