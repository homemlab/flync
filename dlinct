#!/bin/bash
version=0.5

set -e
echo -e '\n'SOFTWARE VERSION $version'\n'
echo -e "Ricardo F. dos Santos <ricardo.santos@nms.unl.pt>\n"
echo -e '\n'Built with Ensembl BDGP6.32 release '('D. melanogaster')'


#ARGS=$(getopt -o colfpsgatqmh:: -l config::,output::,list::,fastq::,paired::,split::,genome::,annotation::,threads::,quality::,metadata::,help -- "$@")

# Constant or default variables ""
appdir=${PWD}
run_name=$(echo $RANDOM | sha1sum | awk '{print$1}')
threads=2
mapcutoff=50
gz=false
progfile=$appdir/scripts/vlookup.awk

# Colors
RED='\033[0;31m'
RED2='\033[1;31m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
PURPLE2='\033[1;35m'
NC='\033[0m'

usage="usage: $(basename "$0") [-d DIRECTORY] [-l FILE] OR [-f DIRECTORY|-p BOOLEAN] ... [OPT ARGS -csgatqm] | [-h]

${PURPLE2}Discovery of Long Intergenic Non-Coding Transcripts options:${NC}
  FLAG  INPUT   DESCRIPTION
    
    -c  <file>  ${CYAN}RECOMENDED. Dispenses all other options.${NC} Configuration file (YAML format) with arguments for running the pipeline.
    
    -o  <path>  ${RED2}MANDATORY.${NC} Directory to which the results will be outputed to.

    -l  <file>  ${RED2}MANDATORY (if no -f).${NC} File with list of SRA accession numbers one per line.

    -f  <dir>   ${RED2}MANDATORY (if no -l).${NC} Directory containing the fastq reads to be analyzed.

    -p  <bool>  Set to \"true\" or \"false\". Boolian if provided reads are paired-end or not. If false or unset will assum single-end reads.
    
    -s  <str>   (OPTIONAL) Split mode: Run specific parts of the analysis pipeline. Available options are:
                  [map] : Download and map reads against the provided accessions.
                  [map-stats] : Preform the analysis of the mapping statistics and prepares files for assembly step.
                                (Requires [map] to be run beforehand).
                  [assembly] : Perform assembly step and coding probability assessment. Also outputs final results.
                                (Requires [map] & [map-stats]).
                  [kall] : Perform the whole pipeline and run a pseudoalignment against the newly discovered lincRNAs.
                                (Requires -c <metadata.csv>)
                  [clean] : Intended to remove unecessary files after complete run. Will delete data/ folder.

    -g  <file>  (OPTIONAL) File in .fa format of the genome sequence to be used. If not provided, the more recent will be downloaded from Ensembl.org at the date of version build.

    -a  <file>  (OPTIONAL) File in .gtf format of the genome annotation to be used. If not provided, the more recent will be downloaded from Ensembl.org at the date of version build.

    -t  <int>   (OPTIONAL) Number of threads to use during discovery (default = 2).

    -q  <int>   (OPTIONAL) Alignment quality. Minimum percentage of reads aligned to genome during hisat2 mapping (default = 50).

    -m  <file>  (REQUIRED with -s kall) Metadata in the .csv format describing the biological condition for each sample to be compared after pseudoalignment and sleuth DE analysis.

    -h          Show this help message and exit."


# # Return help if no arguments are given
# if [[ $# -eq 0 ]] ; then
#     echo -e "${YELLOW}!!!NO ARGUMENTS PROVIDED!!!${NC}" >&2; echo -e "\n$usage" >&2; exit 1
# fi

# Assign varibles from flags
# eval set -- "$ARGS"

options='d:l:s:g:a:t:m:c:h'
while getopts $options option; do
  case "$option" in
    d) workdir=$(readlink -f $OPTARG'/');;
    l) sra=$(readlink -f $OPTARG);;
    s) mode=$OPTARG;;
    g) genome=$(readlink -f $OPTARG);;
    a) annot=$(readlink -f $OPTARG);;
    t) threads=$OPTARG;;
    m) mapcutoff=$OPTARG;;
    c) metadata=$(readlink -f $OPTARG);;
    h) echo "$usage"; exit;;
    :) printf "missing argument for -%s\n" "$OPTARG" >&2; echo "\n$usage" >&2; exit 1;;
    \?) printf "illegal option: -%s\n" "$OPTARG" >&2; echo "\n$usage" >&2; exit 1;;
  esac
done

options="c:o:l:f:p:s:g:a:t:q:m:h:"
while getopts "$options" option
do 	
  case $option in
		c)	
      config=$(readlink -f "$OPTARG");;
		o)	
      workdir=$(readlink -f "$OPTARG");;
		l)	
      sra=$(readlink -f "$OPTARG");;
		f)	
      fq=$(readlink -f "$OPTARG");;
		p)	
      paired="$OPTARG";;
		s)	
      mode="$OPTARG";;
		g)	
      genome=$(readlink -f "$OPTARG");;
		a)	
      annot=$(readlink -f "$OPTARG");;
		t)	
      threads="$OPTARG";;
		q)	
      mapcutoff="$OPTARG";;
		m)	
      metadata=$(readlink -f "$OPTARG");;
    h) echo "$usage"; exit;;
    :) printf "missing argument for -%s\n" "$OPTARG" >&2; echo "\n$usage" >&2; exit 1;;
    \?) printf "illegal option: -%s\n" "$OPTARG" >&2; echo "\n$usage" >&2; exit 1;;
    esac
done

echo $workdir

### Prepare conda to switch between environments
conda_path=$(conda info | grep -i 'base environment' | awk '{print$(4)}')
conda_sh=$conda_path'/etc/profile.d/conda.sh'
source $conda_sh
conda init $(echo $SHELL | awk -F'[/]' '{print$(NF)}') &> $appdir/cmd.out

# Initialize first environment
conda activate infoMod

## Silence citation output of GNU Parallel ##
## SILENCE PARALLEL FIRST RUN ##
# parallel --citation &> $appdir/cmd.out
# echo will cite &> $appdir/cmd.out
# rm $appdir/cmd.out

# Parse arguments from config.yaml if provided
if ! [ -z ${config+x} ]; then
  echo -e "${YELLOW}Getting configuration from .yaml file${NC}"
  run_name=$(niet ".name" "$config")
  workdir=$(readlink -f $(niet ".output" "$config"))
  fq_bool=$(niet ".fastq.active" "$config")
  fq=$(readlink -f $(niet ".fastq.path" "$config"))
  paired=$(niet ".fastq.paired" "$config")
  sra=$(readlink -f $(niet ".fastq.sra" "$config"))
  split_bools=$(niet ".split.active" "$config")
  mode=$(niet ".split.step" "$config")
  genome_bool=$(niet ".genome.active" "$config")
  genome=$(readlink -f $(niet ".genome.sequence" "$config"))
  annot=$(readlink -f $(niet ".genome.annotation" "$config"))
  threads=$(niet ".threads" "$config")
  mapcutoff=$(niet ".map_cutoff" "$config")
  metadata=$(readlink -f $(niet ".split.metadata" "$config"))
fi
echo $workdir

# mandatory arguments
if [ -z ${workdir+x} ]; then 
  echo "$usage" && echo "You need to provide an output directory, if it doesn't exist it will be created" >&2; exit 1 
else
  if ! [[ -d "$workdir" ]]; then
    mkdir -p $workdir
  fi

  if [[ -z ${sra+x} ]]; then
    if [[ -z ${fq+x} ]]; then
      echo "$usage" && echo "You need to provide at least one of the two -l or -f flags - an SRA accession list or a directory containing the fastq files, respectively" >&2; exit 1
    else
      if [[ $(ls "$fq" | grep .fq.gz) ]]; then 
        ls -A "$fq"/*.fq.gz > $apdir/files.txt
        gz=true
      elif [[ $(ls "$fq" | grep .fq) ]]; then 
        ls -A "$fq"/*.fq > $apdir/files.txt
      elif [[ $(ls "$fq" | grep .fastq.gz) ]]; then 
        ls -A "$fq"/*.fastq.gz > $apdir/files.txt
        gz=true
      elif [[ $(ls "$fq" | grep .fastq) ]]; then 
        ls -A "$fq"/*.fastq > $apdir/files.txt
      fi
    jobs=$(wc -l $appdir/files.txt | cut -f1 -d' ')
    fi
  else
    $appdir/scripts/get-sra-info.sh $workdir $sra
    jobs=$(wc -l $sra | cut -f1 -d' ')
  fi
fi

downstream_threads=$(expr $threads / $jobs)
downstream_threads=${downstream_threads%.*}

echo 'Number of threads per task: ' $downstream_threads

# Test if variables are what they are suposed to be #
int='^[0-9]+$'

if ! [[ -d $workdir ]]; then
  echo "-o must be a DIRECTORY to output results and temp files"
  echo "$usage" >&2; exit 1
elif ! [[ -f $sra ]]; then
  echo "-l must be a FILE, usually a .txt file, with SRA accession numbers (SRR######, one per line, last line required to be empty)"
  echo "$usage" >&2; exit 1
elif ! [[ -d $fq ]]; then
  echo "-f must be a DIRECTORY containing with the fastq reads to input"
  echo "$usage" >&2; exit 1
elif ! [[ $threads =~ $int ]]; then
  echo "-t must be an INTEGER with the number of threads to be created during the process (recomended max = number of cores)"
  echo "$usage" >&2; exit 1
elif ! [[ $mapcutoff =~ $int ]]; then
  echo "-m must be an INTEGER defining the minimum percentage of aligned reads for a run to be considered for transcriptome assembly"
  echo "$usage" >&2; exit 1
elif ! [[ -f $metadata ]]; then
  echo "-c must be a .csv file in the format: SRA_sample,condition"
  echo "$usage" >&2; exit 1
fi

# Checking if user supplied genome/annotation files
mkdir -p $appdir/genome

if [[ -z $genome ]]; then
  if ! [[ -z $annot ]]; then
    echo "To avoid compatibility errors .fa and .gtf files should com from same assembly. Using pre-built genome assembly"
    bash $appdir/scripts/get-genome.sh $appdir
    genome=$appdir/genome/genome.fa
    annot=$appdir/genome/genome.gtf
  else
    bash $appdir/scripts/get-genome.sh $appdir
    genome=$appdir/genome/genome.fa
    annot=$appdir/genome/genome.gtf
  fi
else
  if [[ -z $annot ]];then
    echo "To avoid compatibility errors .fa and .gtf files should com from same assembly. Using pre-built genome assembly"
    bash $appdir/scripts/get-genome.sh $appdir
    genome=$appdir/genome/genome.fa
    annot=$appdir/genome/genome.gtf
  else
    if ! [[ -f $annot ]]; then
      echo "-a must be a FILE in the .gtf format"
      echo "$usage" >&2; exit 1
    elif ! [[ -f $genome ]]; then
      echo "-g must be a FILE in the .fa format"
      echo "$usage" >&2; exit 1
    else
      echo "Using user supplied Genome/Annoation assembly"
      rm -rf $appdir/genome/genome*
      cp -f $genome $appdir/genome/genome.fa
      cp -f $annot $appdir/genome/genome.gtf
    fi
  fi
fi

# Initialize alignment environment
conda activate mapMod

### Build genome index
$appdir/scripts/build-index.sh $appdir $threads

### Testing which mode is active and then runing the appropriate pipeline

if [[ $mode = "map" ]]; then
  bash $appdir/scripts/build-index.sh $appdir $threads
  wait
  bash $appdir/scripts/get-sra-info.sh $workdir $sra
  wait
  bash $appdir/scripts/map-sra-list.sh $workdir $sra $threads $appdir
elif [[ $mode = "map-stats" ]]; then
  bash $appdir/scripts/pre-process-mapping-stats.sh $workdir
  wait
  python3 $appdir/scripts/map-stats.py $mapcutoff $workdir
elif [[ $mode = "assembly" ]]; then
  sra2=$workdir/results/filtered_list.txt
  bash $appdir/scripts/transcriptome-assembly.sh $workdir $sra2 $appdir
  wait
  bash $appdir/scripts/coding-prob.sh $workdir
  wait
  bash $appdir/scripts/post-process-transcript-assembly.sh $workdir $progfile
elif [[ $mode = "clean" ]]; then
  rm -rf $workdir/data
elif [[ $mode = "kall" ]]; then
  if [ ! "$metadata" ]; then
    echo "Mandatory arguments -c must be provided"
    echo "$usage" >&2; exit 1
  else
    bash $appdir/scripts/build-index.sh $appdir $threads
    wait
    bash $appdir/scripts/get-sra-info.sh $workdir $sra
    wait
    bash $appdir/scripts/map-sra-list.sh $workdir $sra $threads $appdir
    wait
    bash $appdir/scripts/pre-process-mapping-stats.sh $workdir
    wait
    python3 $appdir/scripts/map-stats.py $mapcutoff $workdir
    sra2=$workdir/results/filtered_list.txt
    wait
    bash $appdir/scripts/transcriptome-assembly.sh $workdir $sra2 $appdir
    wait
    bash $appdir/scripts/coding-prob.sh $workdir
    wait
    bash $appdir/scripts/post-process-transcript-assembly.sh $workdir $progfile
    wait
    bash $appdir/scripts/kallisto.sh $workdir $sra2 $appdir $threads
    wait
    bash $appdir/scripts/pre-process-sleuth.sh $workdir $sra2 $metadata
    metadata2=$workdir/results_dea/metadata.csv
    wait
    Rscript $appdir/scripts/sleuth.r $workdir $metadata2
  fi
elif [[ -z $mode ]]; then
  bash $appdir/scripts/build-index.sh $appdir $threads
  wait
  bash $appdir/scripts/get-sra-info.sh $workdir $sra
  wait
  bash $appdir/scripts/map-sra-list.sh $workdir $sra $threads $appdir
  wait
  bash $appdir/scripts/pre-process-mapping-stats.sh $workdir
  wait
  python3 $appdir/scripts/map-stats.py $mapcutoff $workdir
  sra2=$workdir/results/filtered_list.txt
  wait
  bash $appdir/scripts/transcriptome-assembly.sh $workdir $sra2 $appdir
  wait
  bash $appdir/scripts/coding-prob.sh $workdir
  wait
  bash $appdir/scripts/post-process-transcript-assembly.sh $workdir $progfile
else
  echo "Available options for -s/--split are: [map], [map-stats], [assembly], [clean] or [kall]"
  echo "Run dlinct -h to get help message. To run whole analysis remove -s flag" >&2; exit 1
fi

cp $workdir/assemblies/merged.gtf $workdir/results/merged-assembly.gtf
